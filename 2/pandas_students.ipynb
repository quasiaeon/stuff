{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c596047",
   "metadata": {},
   "source": [
    "# Meteoroloģisko datu apstrāde ar bibliotēku \"Pandas\"\n",
    "\"Pandas\" ir \"Python\" bibliotēka, kas ļauj ērti apstrādāt 2d datu masīvus. \"Pandas\" apvieno funkcijas no \"Excel\" un \"SQL\". Darba lapā apskatītas \"Pandas\" funkcijas, kas būtu noderīgas meteoroloģisko datu apstrādē. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5888d",
   "metadata": {},
   "source": [
    "Vispirms importēsim nepieciešamās bibliotēkas.\n",
    "\n",
    "`pandas` ir bibliotēka, uz kuru fokusēsimies šajā nodarbībā\n",
    "\n",
    "`numpy` ir bibliotēka, kuru izmanto zinātnisko aprēķinu veikšanai\n",
    "\n",
    "`matplotlib.pyplot` ir bibliotēka, kuru izmantosim rezultātu vizualizācijai\n",
    "\n",
    "`seaborn` ir vēl viena bibliotēka, ko izmanto datu vizualizācijai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6ad615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e30de2",
   "metadata": {},
   "source": [
    "## Pandas sintakses pamati\n",
    "Bibliotēka `pandas` ļauj ielasīt datu masīvus gan no teksta failiem, izmantojot `read_csv()`, gan no excel failiem, izmantojot `read_excel`. Standarta \\*.csv failos masīva elementi ir atdalīti ar komatiem (,). Vēlāk tiks parādīts, kā rīkoties, ja failos dati ir formatēti citādāk. </br>\n",
    "Apskatīsim piemēru, kurā tiks nolasīts un apstrādāts fails `stacijas.csv`, kurš satur informāciju par 22 meteoroloģisko novērojumu stacijām Latvijā. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb89073",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stacijas.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stacijas \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstacijas.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atsve\\Desktop\\work\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atsve\\Desktop\\work\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\atsve\\Desktop\\work\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atsve\\Desktop\\work\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\atsve\\Desktop\\work\\.venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stacijas.csv'"
     ]
    }
   ],
   "source": [
    "stacijas = pd.read_csv('stacijas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7ca82",
   "metadata": {},
   "source": [
    "Lai apskatītu `pandas` masīvu var izmantot gan komandu `print` gan vienkārši norādīt masīva nosaukumu. Gadījumā, ja tiek vienkārši norādīts masīva nosaukums, masīvs tiek izvadīts interaktīvas tabulas veidā. Ja tiek izmantota komanda `print`, tad masīvs tiek izvadīts teksta veidā."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacijas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacijas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24933d62",
   "metadata": {},
   "source": [
    "## Pandas masīva izveide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929c138",
   "metadata": {},
   "source": [
    "`pandas` masīvus var ne tikai ielasīt no faila, bet arī izveidot pats, izmantojot `pd.DataFrame()`. Lai izveidotu `pandas` masīvu, nepieciešams uzdot:\n",
    "\n",
    "1) 1d masīvu ar kolonnu nosaukumiem (`columns`) garumā $n$.\n",
    "\n",
    "2) 1d masīvu ar rindu nosaukumiem (`index`) garumā $m$.\n",
    "\n",
    "3) 2d masīvu ar datiem (`data`). Masīvam jābūt ar izmēriem $m \\times n$.\n",
    "\n",
    "Tradicionāli piekļūt masīvu elementiem var pēc to elementu indeksiem, kas dažos gadījumos var būt neērti. `pandas` ļauj masīvu rindām un kolonnām dot nosaukumus, kas padara ērtāku piekļuvi konkrētajiem masīvu elementiem. Vēlāk apskatīsim piemēru, kurā dati tiek glabāti ar konkrētiem laika momentiem un indeksācija ar datumiem padarīs darbu ar datiem krietni vienkāršāku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b27054",
   "metadata": {},
   "source": [
    "Izveidosim `pandas` masīvu, ar indeksu no 1 līdz 4, kolonnām A, B, C un datiem, kas sastāv no tabulas ar skaitļiem no 1 līdz 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(4)\n",
    "columns = ['A', 'B', 'C']\n",
    "data = np.array([[1,  2,  3],\n",
    "                 [4,  5,  6],\n",
    "                 [7,  8,  9],\n",
    "                 [10, 11, 12]])\n",
    "\n",
    "df = pd.DataFrame(data=data, index=index, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc473799",
   "metadata": {},
   "source": [
    "Izveidosim `pandas` masīvu ar gadījuma skaitļiem. Ar komandu `np.random.rand(4, 3)` tiek izveidota 4x3 tabula ar gadījuma skaitļiem robežās starp 0 un 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(4)\n",
    "columns = ['A', 'B', 'C']\n",
    "data = np.random.rand(4, 3)\n",
    "\n",
    "df = pd.DataFrame(data=data, index=index, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9c6c4",
   "metadata": {},
   "source": [
    "Masīvus var ērti saglabāt teksta failos, izmantojot `.to_csv()` vai excel failos, izmantojot `.to_excel()`. Saglabāsim mūsu masīvu failā `test.csv`. Failu var atrast tajā pat mapē, kurā atrodas `.ipynb` darba lapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa132d0",
   "metadata": {},
   "source": [
    "## Piekļūšana Pandas masīva elementiem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21680e1",
   "metadata": {},
   "source": [
    "`pandas` masīvu elementiem var piekļūt 3 dažādos veidos\n",
    "* Aiz punkta norādot vēlamās kolonnas nosaukumu un tad kvadrātiekavās vēlamā elementa numuru\n",
    "* Ar `loc` var piekļūt masīva elementiem pēc to indeksa un kolonnas nosaukuma\n",
    "* Ar `iloc` var piekļūt masīva elementiem līdzīgi kā ar tradicionālo masīvu indeksāciju\n",
    "\n",
    "Piemērā parādīts, kā 3 dažādos veidos piekļūt masīva elementam `Ainazi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b723374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stacijas.station[0])\n",
    "print(stacijas.loc[0, 'station'])\n",
    "print(stacijas.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1148f4e",
   "metadata": {},
   "source": [
    "Tāpat ir iespējams piekļūt arī visai rindai/kolonnai, attiecīgo masīva elementa indeksu aizstājot ar `:`. Piemērā parādīti 3 veidi, kā piekļūt visu novērojumu staciju nosaukumiem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18dafcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(stacijas.station)\n",
    "print(stacijas.loc[:, 'station'])\n",
    "print(stacijas.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8637ea",
   "metadata": {},
   "source": [
    "**Uzdevums:** Izmantojot apakšā doto kodu, izveidot tabulu `cilveki`. Uzrakstīt kodu, kas visos trīs veidos piekļūst Annas vecumam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100413cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdzimums\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvecums\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautovaditaja_aplieciba\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m19\u001b[39m,\u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[0;32m      4\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m21\u001b[39m,\u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[0;32m      5\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m25\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m],\n\u001b[0;32m      6\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m22\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m]]\n\u001b[1;32m----> 8\u001b[0m cilveki \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mdata, index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m      9\u001b[0m cilveki\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "index = ['Jānis', 'Anna', 'Ilze', 'Pēteris']\n",
    "columns = ['dzimums', 'vecums', 'autovaditaja_aplieciba']\n",
    "data = [['V',19,True],\n",
    "        ['S',21,True],\n",
    "        ['S',25,False],\n",
    "        ['V',22,False]]\n",
    "\n",
    "cilveki = pd.DataFrame(data=data, index=index, columns=columns)\n",
    "cilveki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34499c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "509c57df",
   "metadata": {},
   "source": [
    "## Datu atlasīšana\n",
    "Dažreiz var būt nepieciešams no datu masīva atlasīt rindas, kuras atbilst noteiktiem kritērijiem. Piemēram, mēs vēlamies salīdzināt gaisa temperatūru novērojumu stacijās, kuras atrodas augstienēs ar temperatūru stacijās, kuras atrodas zemienēs. Šajā piemērā izvēlēsimies novērojumu stacijas, kuras atrodas augstumā zem 10 metriem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b586494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacijas[stacijas.elevation<10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cf9e7",
   "metadata": {},
   "source": [
    "Starp kritērijiem var veikt loģiskas operācijas. AND apzīmē reizināšanas zīmi (\\*), OR apzīmē ar vertikālu svītru (|), NOT apzīmē ar tildi (~). Izvēlēsimies stacijas augstumā starp 10 un 100 metriem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacijas[(stacijas.elevation>10)*(stacijas.elevation<100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6c343",
   "metadata": {},
   "source": [
    "**Uzdevums**: Izvēlēties tās novērojumu stacijas, kuru ģeogrāfiskais garums (`lon`) ir starp 24 un 26 un kuras atrodas augstumā zem 50 metriem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c820abce",
   "metadata": {},
   "source": [
    "## Darbības ar datumiem\n",
    "Pandas dod iespēju strādāt ar datumiem kā atsevišķu datu tipu. Tas padara darbu ar laikrindām ērtāku. Pandas atbalsta divus datu tipus, kas saistīti ar datumiem – `Timestamp` jeb laika moments un `Timedelta` jeb laika intervāls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52827c92",
   "metadata": {},
   "source": [
    "Nodefinēsim divus laika momentus. `date1` mainīgajam piešķirsim 2023. gada 16. aprīļa pusnakti. `date2` mainīgajam piešķirsim pašreizējo laika momentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.to_datetime(\"2023-04-16 00:00:00\")\n",
    "date2 = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45834d28",
   "metadata": {},
   "source": [
    "`dt` mainīgajam piešķirsim laika intervālu 12 dienas un 5 stundas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c97ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.Timedelta(days=12, hours=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8be073",
   "metadata": {},
   "source": [
    "Par laika momenta mainīgo var iegūt informāciju, piemēram, gadu (year), mēnesi (month), dienu (hour), stundu(hour), nedēļas dienu (dayofweek), dienu no gada sākuma (dayofyear). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date1.dayofyear)\n",
    "print(date1.dayofweek) # 0 - pirmdiena, 6 - svētdiena\n",
    "print(date1.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74e632",
   "metadata": {},
   "source": [
    "Ir pieejams plašs darbību klāsts ar šiem datu tipiem. Pieejamās darbības var izsecināt, domājot par tām kā par fizikāliem lielumiem ar savām mērvienībām."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laika soli var pareizināt ar skaitli\n",
    "print(dt*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laika soļus var saskaitīt\n",
    "print(dt + dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izdalot vienu laika soli ar otru, iegūst skaitli. Var izmantot, lai saskaitītu dienas/stundas starp diviem datumiem.\n",
    "print(dt/pd.Timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72dcf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laika momentam var pieskaitīt laika soli\n",
    "print(date1+dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laika momentus var atņemt vienu no otra un iegūt laika soli\n",
    "print(date2-date1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laika momentus var salīdzināt, kurš ir agrāks\n",
    "print(date1>date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laika momentiem ir pieejams range() ekvivalents. Var uzdod sākumu, intervālu, intervālu skaitu, beigas. \n",
    "print(pd.date_range(start='2018-01-01', end='2018-01-02', freq='3h'))\n",
    "print(pd.date_range(start='2018-01-01', end='2018-01-02', periods=9))\n",
    "print(pd.date_range(start='2018-01-01', freq='3h', periods=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9838c6f4",
   "metadata": {},
   "source": [
    "Pandas ļauj strādāt ar laika momentiem dažādās laika zonās. Iepriekšējā piemērā tika strādāts ar laika momentiem, kuri nesatur informāciju par laika zonu. Izmantojot `.tz_localize()`, laika momentam var piešķirt konkrētu laika zonu, šajā gadījumā Rīgas laiku. Tas iekļauj sevī pāreju uz vasaras/ziemas laiku, kā arī laika zonas maiņu pēc PSRS sabrukuma.\n",
    "\n",
    "Pagriežot pulksteni stundu atpakaļ, var rasties zināmas problēmas. Pieņemsim, ka pulksten 4:00 pulkstenis tiek pagriezts stundu atpakaļ, lai pārietu uz ziemas laiku. Tāpēc tajā dienā būs divi brīži, kad pulkstenis rādīs 3:00. Lai tas neradītu kļūdu, nepieciešams norādīt parametru `ambiguous`. Gadījumā, ja `ambiguous=True`, šādi brīži tiek skatīti pēc ziemas laika, bet, ja `ambiguous=False`, šādi brīži tiek skatīti pēc vasaras laika.\n",
    "\n",
    "Izmantojot `.tz_convert()`, ir iespējams konvertēt laika momentu uz citu laika zonu. Jāņem vērā, ka, ja viens laika moments satur informāciju par laika zonu, bet otrs nesatur, tad starp tiem nav iespējams veikt darbības."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700f83fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.Timestamp.now()\n",
    "print(date1.tz_localize('Europe/Riga', ambiguous=False).tz_convert('UTC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f27f78",
   "metadata": {},
   "source": [
    "**Uzdevumi:**\n",
    "\n",
    "1) Rokgrupas \"Queen\" solists Fredijs Merkūrijs piedzima 1946. gada 5. septembrī un mira 1991. gada 24. novembrī. Izmantojot `pandas` pieejamās iespējas, aprēķini, cik dienas nodzīvoja Fredijs Merkūrijs.\n",
    "\n",
    "2) Izmantojot `pandas` pieejamās iespējas noteikt nedēļas dienu, kurā piedzima Fredijs Merkūrijs.\n",
    "\n",
    "3) Izmantojot `pandas` iespējas, nosaki, kurš laika moments ir vēlāks: 2023. gada 9. februāris 19:00 pēc Ņujorkas, ASV (`America/New_York`) laika vai 2023. gada 10. februāra 06:00 pēc Šanhajas, Ķīna (`Asia/Shanghai`) laika. Pārveidot abus uz Latvijas laiku (`Europe/Riga`).\n",
    "\n",
    "4) 2320. gada 2. februārī es nopirku jaunu datoru, kuram garantijas ilgums ir 1000 dienas. Izmantojot `pandas` iespējas, noteikt datumu, kad datoram beidzās garantija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474316d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284f6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add05010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78c582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3113b4a",
   "metadata": {},
   "source": [
    "## Darbības ar laikrindām\n",
    "Ielasīsim reālu datu failu, kurš satur informāciju par gaisa temperatūras novērojumiem Rīgas meteoroloģiskajā stacijā. Turpmāk apskatīsim noderīgas `pandas` funkcijas, lai varētu apstrādāt šos datus.\n",
    "* Nolasīsim datu failu ar `read_csv`. Pēc noklusējuma atdalītājs starp kolonnām ir komats (,). Šajā gadījumā atdalītājs ir \"tab\" simbols, tāpēc papildus jānorāda `sep='\\t'`.\n",
    "* Izmantojot komandu `df.set_index()` kā datu masīva indeksu izvēlas kolonnu `date`. Norādot `inplace=True`, izmaiņas tiek veiktas mainīgajam `df`. Norādot `inplace=False`, tiek izveidots jauns masīvs, kurš būtu jāsaglabā kādā mainīgajā.\n",
    "* Rindā `df.index = pd.to_datetime(df.index)` datu masīva indekss tiek pārveidots par `Timestamp` datu tipu, kas ļauj ar to ērti veikt darbības.\n",
    "* Tālāk šiem datumiem tiek piešķirta laika zona un šis laiks tiek konvertēts uz GMT-2 laiku, kas atbilst ziemas laikam Latvijā."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cf100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('temperatura/Riga.txt', sep='\\t')\n",
    "df.set_index('date', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.tz_localize('Europe/Riga', ambiguous=False).tz_convert('Etc/GMT-2')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651164a0",
   "metadata": {},
   "source": [
    "Izvēlēsimies laika intervālu starp 1966. un 2018. gadu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.index.year>=1966)*(df.index.year<=2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba967006",
   "metadata": {},
   "source": [
    "Funkcija \"describe\" ļauj iegūt aprakstošo statistiku par skaitļiem datu masīva kolonnās."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc34418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80741152",
   "metadata": {},
   "source": [
    "**Uzdevums:** Izmantojot `loc` piekļūt temperatūrai 2010. gada 15. februārī 11:00 pēc `Etc/GMT-2` laika zonas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b338b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d6c7e1b",
   "metadata": {},
   "source": [
    "## resample/groupby iespējas\n",
    "Pandas ļauj ērti apstrādāt datus un no temperatūras novērojumiem iegūt, piemēram gada vidējo gaisa temperatūru. Pandas ir pieejamas funkcijas `resample` un `groupby`, kuras ļauj ērti veikt datu grupēšanu pa laika periodiem. Groupby veic grupēšanu pēc konkrēta kritērija. Resample veic grupēšanu pa secīgiem laika periodiem. Pēc datu grupēšanas katrai grupai var aprēķināt statistikas, piemēram: \n",
    "* `mean` – vidējā vērtība.\n",
    "* `min`, `max` – mazākā vai lielākā vērtība.\n",
    "* `quantile(q)` – q-tā kvantile. Piemēram 0.1 kvantile nozīmē, ka 10% gadījumu novērotā temperatūra ir mazāka par šo vērtību.\n",
    "* `meadian` – mediāna jeb 0.5 kvantile.\n",
    "*  `sum`, `prod` – summa vai reizinājums.\n",
    "* `count` – skaits.\n",
    "* `std` – standartnovirze.\n",
    "    \n",
    "Turpmākajos piemēros apskatīti vairāki šo funkciju pielietojumi temperatūras laikrindām."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da40172",
   "metadata": {},
   "source": [
    "Piemērs. Katram sekojošam gadam tiek aprēķināta vidējā gaisa temperatūra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784e2db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.resample('Y').mean())\n",
    "plt.grid(which='both')\n",
    "plt.xlabel('Gads')\n",
    "plt.ylabel('$T, ^\\circ C$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09020deb",
   "metadata": {},
   "source": [
    "Piemērs. Katram sekojošam mēnesim tiek aprēķināta vidējā gaisa temperatūra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.resample('M').mean())\n",
    "plt.grid(which='both')\n",
    "plt.xlabel('Gads')\n",
    "plt.ylabel('$T, ^\\circ C$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c979fd9",
   "metadata": {},
   "source": [
    "Piemērs. Visi dati tiek grupēti pēc mēnešiem un katram mēnesim tiek aprēķināta vidējā gaisa temperatūra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de008a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.groupby(df.index.month).mean())\n",
    "plt.grid(which='both')\n",
    "plt.xlabel('Mēnesis')\n",
    "plt.ylabel('$T, ^\\circ C$')\n",
    "plt.xticks(range(1,13))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af18a2",
   "metadata": {},
   "source": [
    "Piemērs. Vispirms sagrupē datus pa 3 stundām. Tas jādara tāpēc, ka laika gaitā ir mainījies novērojumu veikšanas biežums: līdz 2002. gadam reizi 3 stundās, bet pēc 2002. gada – reizi stundā. Sagurpē datus pēc diennakts stundas un katrai stundai tiek aprēķināta vidējā gaisa temperatūra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcccd835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.resample('3h').mean()\n",
    "plt.plot(df2.groupby(df2.index.hour).mean())\n",
    "plt.grid(which='both')\n",
    "plt.xlabel('Stunda')\n",
    "plt.ylabel('$T, ^\\circ C$')\n",
    "plt.xticks(range(0,23,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576050f3",
   "metadata": {},
   "source": [
    "Piemērs. Pandas ļauj grupēt arī pēc vairākiem mainīgajiem reizē. Vispirms sagrupē datus pa 3 stundām. Veic grupešanu gan pa mēnešiem un stundām reizē, katrai grupai aprēķina vidējo vērtību."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.resample('3h').mean()\n",
    "df2 = df2.groupby([df2.index.month, df2.index.hour]).mean()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30def2c8",
   "metadata": {},
   "source": [
    "Redzam, ka dati tagad ir sagrupēti 1d masīvā ar 96 elementiem. Uzskatāmības labad šos datus vizualizēsim kā 2d tabulu. Lai to izdarītu, izveidosim jaunu `pandas` datu masīvu, izmantojot `pd.DataFrame()`. Kā masīva kolonnu nosaukumi būs diennakts stundas ik pa 3 stundām. Kā masīva rindu nosaukumi būs gada mēnešu numuri. Kā masīva datus izmantosim jau iepriekš aprēķinātās vidējās vērtības. Izmantojot `.reshape([12, 8])`, pārveidosim mūsu 96 elementu 1d masīvu par 12x8 elementu 2d masīvu, kura rindas atbilst mēnešu numuriem un kolonnas – diennakts stundām. \n",
    "\n",
    "Vizualizēsim datu masīvu, izmantojot `sns.heatmap()`. `annot=True`, nozīmē, ka tabulas šūnās tiks ierakstīta konkrētā vērtība, izmantojot `fmt='.1f'` pasaka, ka skaitļus izvada 1 zīmi aiz komata. `cmap='viridis'` pasaka mūsu izmantoto krāsu skalu, par kurām plašāk tiks stāstīts lekcijā par datu vizualizāciju. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=np.arange(0, 24, 3), index=np.arange(1, 13), data=np.array(df2).reshape([12, 8]))\n",
    "plt.figure()\n",
    "sns.heatmap(df2, annot=True, cmap='viridis', fmt='.1f')\n",
    "plt.xlabel('Stunda')\n",
    "plt.ylabel('Mēnesis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd54b1",
   "metadata": {},
   "source": [
    "**Uzdevumi.**\n",
    "\n",
    "1) Par sala dienu sauc dienu, kad minimālā gaisa temperatūra ir zem $0^\\circ C$. Aprēķināt un uzzīmēt, kā sala dienu skaits ir mainījies pa gadiem.\n",
    "\n",
    "2) Aprēķināt un uzzīmēt, kā ir mainījusies vasaras (jūn, jūl, aug) vidējā gaisa temperatūra pa gadiem.\n",
    "\n",
    "3) Par vasaras dienu sauc dienu, kad maksimālā gaisa temperatūra pārsniedz $25^\\circ C$. Aprēķināt un uzzīmēt, kā vasaras dienu skaits ir mainījies pa gadiem.\n",
    "\n",
    "4) Aprēķināt un uzzīmēt, kā ir mainījusies diennakts maksimālās temperatūras vidējā vērtība pa gadiem.\n",
    "\n",
    "5) Izmantojot temperatūras datus no 1970. līdz 2000. gadam katrai gada dienai (`dayofyear`) aprēķināt vidējo temperatūru, ko sauksim par gaisa temperatūras normu. Uzzīmēt vienā grafikā diennakts gaisa temperatūras normu un katras diennakts vidējo temperatūru 2016. gadā. Aprēķināt, cik dienās gaisa temperatūra bija virs normas un cik dienās zem normas. Ja nepieciešams, pārveidojiet `pandas` datu masīvus uz `numpy` datu masīviem. Par garajiem gadiem neuztraukties un vienkārši grupēt pēc `dayofyear`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7001f",
   "metadata": {},
   "source": [
    "## Datu masīvu apvienošana\n",
    "Dažreiz nepieciešamie dati neglabājas vienā failā, tāpēc var rasties nepieciešamība apvienot vairākus datu masīvus no vairākiem failiem. Vispirms ielasīsim temperatūras datus Rīgā un Liepājā."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7f9ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('temperatura/Riga.txt', sep='\\t')\n",
    "df1.set_index('date', inplace=True)\n",
    "df1.index = pd.to_datetime(df1.index)\n",
    "df1.columns = ['Riga']\n",
    "\n",
    "df2 = pd.read_csv('temperatura/Liepaja.txt', sep='\\t')\n",
    "df2.set_index('date', inplace=True)\n",
    "df2.index = pd.to_datetime(df2.index)\n",
    "df2.columns = ['Liepaja']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dece475",
   "metadata": {},
   "source": [
    "Datu masīvus var apvienot uz indeksa, izmantojot komandu `.join()`. Opcija `how` ļauj izvēlēties, kurus indeksa elementus saglabāt:\n",
    "\n",
    "* `left` – pirmās kolonnas indekss.\n",
    "* `right` – otrās kolonnas indekss.\n",
    "* `outer` – abu kolonnu indeksu apvienojums.\n",
    "* `inner` – abu kolonnu indeksu šķēlums.\n",
    "\n",
    "Iztrūkstošie gadījumi tiks identificēti kā `NaN`. Pie reizes izvēlēsimies datus starp 1966. un 2018. gadu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.join(df2, how='inner')\n",
    "df = df[(df.index.year>=1966)*(df.index.year<=2018)]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1c1c8",
   "metadata": {},
   "source": [
    "**Uzdevums**: Mapē `temperatura` \\*.txt failos atrodas temperatūras novērojumu dati no meteoroloģiskajām stacijām visā Latvijā. Izmantojot staciju sarakstu no masīva `stacijas`, ielasīt datus no visām stacijām un apvienot tās vienā `pandas` masīvā. To var izdarīt, vispirms ielasot vienas stacijas datus. Tad, ejot ciklā cauri staciju sarakstam, šim masīvam var pievienot pa vienam datus no citām stacijām."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4cdde",
   "metadata": {},
   "source": [
    "Arī gadījumā, ja datu masīvs satur vairākas kolonnas, izmantojot `.describe()` iespējams iegūt statistiku par katru no kolonnām."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46ebcac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1b402",
   "metadata": {},
   "source": [
    "Izmantojot `.groupby()`, iespējams grupēt arī datus ar vairākām kolonnām. Piemērā izveidosim tabulu, kas satur katrai novērojumu stacijai katra mēneša vidējo temperatūru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "sns.heatmap(df.groupby(df.index.month).mean(), annot=True, cmap='viridis', fmt='.1f')\n",
    "plt.xlabel('Stacija')\n",
    "plt.ylabel('Mēnesis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f902e5",
   "metadata": {},
   "source": [
    "## \"Pandas\" un \"Numpy\" salīdzinājums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b3c61",
   "metadata": {},
   "source": [
    "Pandas datu masīvs pēc būtības atgādina 2D numpy masīvu. Tomēr ir vairākas būtiskas atšķirības. Piemēram, numpy masīvā nepieciešams, lai viss masīvs saturētu sevī viena datu tipa mainīgos. Tikmēr pandas masīvā katrai kolonnai var būt savs datu tips. Numpy masīva elementiem var piekļūt pēc to indeksiem. Pandas datu masīva kolonnām var piekļūt pēc to nosaukumiem. Tomēr var izmantot arī tradicionālo indeksāciju, izmantojot `.iloc[]`. Piekļūsim novērojumu staciju nosaukumu sarakstam divos dažādos veidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3826ef",
   "metadata": {},
   "source": [
    "Ja `pandas` datu masīvs satur tikai viena datu tipa mainīgos, to var pārveidot par `numpy` masīvu, izmantojot `np.array()`. Tādā gadījumā pazūd masīva indekss un kolonnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e647f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.array(stacijas.station))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
